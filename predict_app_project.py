# -*- coding: utf-8 -*-
"""predict app project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TNWFIypJcoyegIGRKA3O3owvR9OqS7TU
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import seaborn as sns
from sklearn import metrics
from sklearn.model_selection import train_test_split
import random
import matplotlib.pyplot as plt
# %matplotlib inline

df=pd.read_csv('/content/googleplaystore.csv')

df.head()

df.info()

df.dropna(inplace = True)

df.describe()

df.isnull().sum()

#data explorataion
plt.rcParams['figure.figsize']=[20,5]
sns.heatmap(df.isnull())
plt.show()

x=df['Rating']
y=df['Installs']
plt.scatter(x,y)
plt.show()

x=df['Category']
y=df['Installs']
plt.bar(x,y)
plt.show()

# preprocessing
from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
df['Category']=le.fit_transform(df['Type'])
df

x=df['Installs']
y=df['Type']

for i in df.columns:
  if df[i].dtype=='object':
    df[i] = le.fit_transform(df[i])

#training testing
from sklearn.model_selection import train_test_split
x=df[['Reviews']]
y=df['Reviews']
x_train,x_test,y_train,y_test=train_test_split(x,y,train_size=0.25,random_state=1)

df.dropna(inplace=True)

#Linear regression
from sklearn.linear_model import LinearRegression
log_reg=LinearRegression()
log_reg.fit(x_train,y_train)

y_pred=log_reg.predict(x_test)

#accuracy score
log_reg.score(x_train,y_train)
log_reg.score(x_test,y_test)

sns.distplot((y_test-y_pred),bins=50);

#The k-nearest neighbors algorithm is based around the simple idea of predicting unknown
#values by matching them with the most similar known values.
#Building the model consists only of storing the training dataset. To make a prediction for a new data point, the algorithm finds the closest data points in the training dataset â€” its "nearest neighbors".
from sklearn.neighbors import KNeighborsRegressor
model = KNeighborsRegressor(n_neighbors=15)

from sklearn.model_selection import train_test_split
# Split data into training and testing sets
X = df[['Rating']]
y = df['Rating']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 10)
model.fit(X_train, y_train)

# Calculate the mean accuracy of the KNN model
accuracy = model.score(X_test,y_test)
'Accuracy: ' + str(np.round(accuracy*100, 2)) + '%'

# Try different numbers of n_estimators - this will take a minute or so
n_neighbors = np.arange(1, 20, 1)
scores = []
for n in n_neighbors:
    model.set_params(n_neighbors=n)
    model.fit(X_train, y_train)
    scores.append(model.score(X_test, y_test))
plt.figure(figsize=(7, 5))
plt.title("Effect of Estimators")
plt.xlabel("Number of Neighbors K")
plt.ylabel("Score")
plt.plot(n_neighbors, scores)